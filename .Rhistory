E.dist <- dist(x = inputData, method = "euclidean")
M.dist <- dist(x = inputData, method = "manhattan")
par(mfrow=c(1,2))
h.E.cluster <- hclust(E.dist)
plot(h.E.cluster, xlab="歐式距離",family="黑體-繁 中黑")
h.M.cluster <- hclust(M.dist)
plot(h.M.cluster, xlab="曼哈頓距離", family="黑體-繁 中黑")
#刪除標籤欄位
inputData<-iris[,-5]
head(inputData)
#不同的資料點間距離矩陣的運算
E.dist <- dist(x = inputData, method = "euclidean")
M.dist <- dist(x = inputData, method = "manhattan")
par(mfrow=c(1,2))
h.E.cluster <- hclust(E.dist)
plot(h.E.cluster, xlab="歐式距離",family="黑體-繁 中黑")
h.M.cluster <- hclust(M.dist)
plot(h.M.cluster, xlab="曼哈頓距離", family="黑體-繁 中黑")
dev.off()
par(mfrow= c(3,2),family="黑體-繁 中黑")
plot(hclust(E.dist, method="single"),xlab = "最近聚合法:single-linkage")   # 最近法
plot(hclust(E.dist, method="complete"), xlab = "最遠聚合法:complete-linkage")  # 最遠法
plot(hclust(E.dist, method="average"), xlab = "平均聚合法: average-linkage")  # 平均法
plot(hclust(E.dist, method="centroid"), xlab = "中心法: centroid-linkage") # 中心法
plot(hclust(E.dist, method="ward.D2"), xlab = "華德法: Ward's Method")  # 華德法
dev.off()
par(family="黑體-繁 中黑")
plot(hclust(E.dist, method="ward.D2"), xlab = "華德法: Ward's Method")
# Compute with agnes
library(cluster)
hc2 <- agnes(E.dist, method = "ward")
hc2$ac
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
ac <- function(x) {
agnes(E.dist, method = x)$ac
}
map_dbl(m, ac) #Apply a function to each element of a vector
#繪圖
dev.off()
hc2 <- agnes(E.dist, method = "ward")
pltree(hc2, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
h.E.Ward.cluster <- hclust(E.dist, method="ward.D2")
plot(h.E.Ward.cluster)
rect.hclust(tree =h.E.Ward.cluster, k = 3, border = "red")
rect.hclust(tree =h.E.Ward.cluster, k = 13, border = "blue")
h.E.Ward.cluster <- hclust(E.dist, method="ward.D2")
plot(h.E.Ward.cluster)
rect.hclust(tree =h.E.Ward.cluster, h = 4, border = "red")
rect.hclust(tree =h.E.Ward.cluster, h = 10, border = "blue")
h.E.Ward.cluster <- hclust(E.dist, method="ward.D2")
cut.h.cluster <- cutree(tree = h.E.Ward.cluster, k = 3)
cut.h.cluster
table(cut.h.cluster, iris$Species)
plot(table(iris$Species, cut.h.cluster),
main = "Confusion Matrix for Species Clustering",
xlab="Species",ylab="Cluster")
#原始資料分布情況
ggplot(data = iris,
mapping = aes(x = Petal.Length, y = Petal.Width)) +
geom_point(aes(col = Species))
head(USArrests)
inputData<-USArrests%>%na.omit()%>%scale()
diana_cluster<-diana(inputData)
diana_cluster$dc
pltree(diana_clust, cex = 0.6,
hang = -1, main = "Dendrogram of diana")
# plot dendrogram
pltree(diana_cluster, cex = 0.6,
hang = -1, main = "Dendrogram of diana")
# Cut diana() tree into 4 groups
diana_cluster <- diana(inputData)
group <- cutree(diana_cluster, k = 4)
group
library(factoextra)
install.packages('factoextra')
library(factoextra)
fviz_cluster(list(data = inputData, cluster = group))
fviz_nbclust(inputData,
FUN = hcut, #階層式分群法
method = "wss")#組內平方誤差
fviz_nbclust(x = inputData,
FUNcluster = hcut,
method = "silhouette")
gap_stat <- clusGap(x = inputData,
FUNcluster = hcut,
nstart = 25,
K.max = 10,
B = 50)
fviz_gap_stat(gap_stat)
library(dplyr)
library(magrittr)   #pipelines
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
inputData <-
USArrests %>%
na.omit() %>% # 忽略遺失值
scale() # 資料標準化
head(inputData)
distance <- get_dist(x = inputData)
fviz_dist(dist.obj = distance,
gradient = list(
low = "#00AFBB",
mid = "white",
high = "#FC4E07"))
set.seed(101)
k_clust <- kmeans(inputData, centers = 2, nstart = 25)
str(k_clust)
fviz_cluster(k_clust, data = inputData)
inputData %>%
as_tibble() %>%
mutate(cluster = k_clust$cluster, #新增分群結果
state = row.names(USArrests) #將列名稱指定為原始資料標籤
) %>%
ggplot(aes(UrbanPop, Murder, color = factor(cluster), label = state)) +
#使用ggplot套件繪圖（指定x,y軸），標記國家名稱，並依據分群結果上色
geom_text()
set.seed(101)
k_clust <- kmeans(inputData, centers = 2, nstart = 25)
k_clust_3 <- kmeans(inputData, centers = 3, nstart = 25)
k_clust_4 <- kmeans(inputData, centers = 4, nstart = 25)
k_clust_5 <- kmeans(inputData, centers = 5, nstart = 25)
# plots to compare
p1 <- fviz_cluster(k_clust, geom = "point", data = inputData) + ggtitle("k = 2")
p2 <- fviz_cluster(k_clust_3, geom = "point",  data = inputData) + ggtitle("k = 3")
p3 <- fviz_cluster(k_clust_4, geom = "point",  data = inputData) + ggtitle("k = 4")
p4 <- fviz_cluster(k_clust_5, geom = "point",  data = inputData) + ggtitle("k = 5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
kmedoid.cluster <- pam(x = inputData, #數值矩陣、data frame、相異度矩陣
k=3,          #分群數目
diss=FALSE,  #是否為相異度矩陣
# metric=”euclidean”   #計算相異度矩陣的距離方式
)
fviz_cluster(kmedoid.cluster, data = inputData,main = 'K-Medoid')
View(inputData)
str(inputData)
kmedoid.cluster <- pam(x = inputData, #數值矩陣、data frame、相異度矩陣
k=3,          #分群數目
#diss=FALSE,  #是否為相異度矩陣
# metric=”euclidean”   #計算相異度矩陣的距離方式
)
fviz_cluster(kmedoid.cluster, data = inputData,main = 'K-Medoid')
# 繪製側影圖
plot(kmedoid.cluster,which.plots = 2)
wss <- function(k) {
kmeans( x = inputData,
centers =  k,
nstart = 10 )$tot.withinss
}
wss
k.values
k.values <- 1:15
wss_values <- map_dbl(k.values, wss)
wss_values
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
#將上述數行程式碼縮減到一行指令:
set.seed(123)
fviz_nbclust(x = inputData,FUNcluster = kmeans, method = "wss")
km.res <- kmeans(x = inputData,
centers = 5,
nstart = 25)
km.res$cluster
ss <- silhouette(km.res$cluster, dist(inputData))
ss
mean([,3])
#取整體平均:
mean(ss[ ,3])
plot(ss)
avg_sil <- function(k) {
km.res <- kmeans(x = inputData, centers = k, nstart = 25)
ss <- silhouette(km.res$cluster, dist(inputData))
mean(ss[, 3])
}
# Compute and plot wss for k = 2 to k = 15
k.values <- 2:15
# extract avg silhouette for 2-15 clusters
avg_sil_values <- map_dbl(k.values, avg_sil)
avg_sil_values
plot(k.values, avg_sil_values,
type = "b", pch = 19, frame = FALSE,
xlab = "Number of clusters K",
ylab = "Average Silhouettes")
fviz_nbclust(inputData, kmeans, method="silhouetee")
#使用fviz_nbclust函數將上述程式碼指令濃縮成一行:
fviz_nbclust(inputData, kmeans, method="silhouette")
set.seed(123)
gap_stat <- clusGap(x = inputData,
FUN = kmeans,
nstart = 25,
K.max = 10,
B = 50)
# Print the result
print(gap_stat, method = "firstmax") #找最大化Gap(k)的最小k值
fviz_gap_stat(gap_stat)
(!is.na(pizza$week))
data("BostonHousing",package="mlbench")
set.seed(100)
BostonHousing[sample(1:nrow(BostonHousing),40),"rad"] <- NA
BostonHousing[sample(1:nrow(BostonHousing),40), "ptratio"] <- NA
head(BostonHousing,15)
install.packages("mice")
library(mice)
install.packages("mice")
install.packages("backports")
install.packages("mice")
install.packages("mice")
setRepositories()
complete.cases(data)
# 刪除資料列法
data
BostonHousing
data("BostonHousing",package="mlbench")
BostonHousing
data("BostonHousing",package="mlbench")
data<-BostonHousing
# 刪除資料列法
data
complete.cases(data)
data[!complete.cases(data),]
data[complete.cases(data),]
# 刪除資料列法
data_backup<-data
# 刪除資料列法
data_backup<-data
data_backup[!complete.cases(data_backup),]<-NULL
data_backup
data
str(data)
data_backup
str(data_backup)
data_backup<-data
data_backup[!complete.cases(data_backup),]
complete.cases(data_backup)
data("BostonHousing",package="mlbench")
data<-BostonHousing
set.seed(100)
BostonHousing[sample(1:nrow(BostonHousing),40),"rad"] <- NA
BostonHousing[sample(1:nrow(BostonHousing),40), "ptratio"] <- NA
head(BostonHousing,15)
data_backup<-data
complete.cases(data_backup)
data_backup
data("BostonHousing",package="mlbench")
data<-BostonHousing
str(data)  #'data.frame':	506 obs. of  14 variables
set.seed(100)
data[sample(1:nrow(data),40),"rad"] <- NA
data[sample(1:nrow(data),40), "ptratio"] <- NA
head(data,15)
data_backup<-data
complete.cases(data_backup)
data_backup[!complete.cases(data_backup),]
data_backup[!complete.cases(data_backup),] <-NULL
MissingValue_Row<-data_backup[!complete.cases(data_backup),]
MissingValue_Row
data_backup<-data_backup[complete.cases(data_backup),]
data_backup
str(data_backup)
install.packages("Hmisc")
data_backup2<-data
data_backup2$ptratio[is.na(data_backup2$ptratio)=TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
install.packages("DMwR")
actuals <- data$ptratio[is.na(data$ptratio)]
actuals
data$ptratio
actuals <- data$ptratio[is.na(data$ptratio)]
predicteds <- rep(mean(data$ptratio, na.rm = TRUE), length(actuals))
predicteds
str(actuals)
str(predicteds)
regr.eval(trues = actuals,preds = predicteds)
install.packages("DMwR")
data_backup2
# Hand:
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
data_backup2$ptratio
install.packages("Hmisc")
install.packages("DMwR")
library(DMwR)
install.packages('DMwR')
data("BostonHousing",package="mlbench")
data<-BostonHousing
set.seed(100)
data[sample(1:nrow(data),40),"rad"] <- NA
data[sample(1:nrow(data),40), "ptratio"] <- NA
head(data,15)
install.packages('Hmisc')
install.packages("Hmisc")
install.packages('Hmisc')
data("BostonHousing",package="mlbench")
data<-BostonHousing
str(data)  #'data.frame':	506 obs. of  14 variables
install.packages('DMwR')
library(DMwR)
# 填補法
data_backup2<-data
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
actuals <- data$ptratio[is.na(data$ptratio)]
actuals
data
data("BostonHousing",package="mlbench")
data<-BostonHousing
str(data)  #'data.frame':	506 obs. of  14 variables
set.seed(100)
data[sample(1:nrow(data),40),"rad"] <- NA
data[sample(1:nrow(data),40), "ptratio"] <- NA
head(data,15)
data_backup2<-data
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
actuals <- data$ptratio[is.na(data$ptratio)]
actuals
predicteds <- rep(mean(data_backup2$ptratio, na.rm = TRUE), length(actuals))
predicteds
predicteds <- rep(mean(data$ptratio, na.rm = TRUE), length(actuals))
predicteds
regr.eval(trues = actuals,preds = predicteds)
data("BostonHousing", package = "mlbench")
original <- BostonHousing
set.seed(100)
BostonHousing[sample(1:nrow(BostonHousing),40),"rad"] <- NA
BostonHousing[sample(1:nrow(BostonHousing),40), "ptratio"] <- NA
head(BostonHousing)
original<-BostonHousing
actuals <- original$ptratio[is.na(original$ptratio)]
actuals
predicteds <- rep(mean(data_backup2$ptratio, na.rm = TRUE), length(actuals))
predicteds
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
data_backup2$ptratio
original$ptratio
BostonHousing
data("BostonHousing",package="mlbench")
data<-BostonHousing
BostonHousing
original$ptratio
original
complete.cases(original)
data("BostonHousing",package="mlbench")
data<-BostonHousing
original<-BostonHousing
str(data)  #'data.frame':	506 obs. of  14 variables
complete.cases(original)
set.seed(100)
data[sample(1:nrow(data),40),"rad"] <- NA
data[sample(1:nrow(data),40), "ptratio"] <- NA
head(data,15)
complete.cases(data)
data_backup2<-data
data_backup2$ptratio[is.na(data_backup2$ptratio)==TRUE]<-mean(data_backup2$ptratio, na.rm=TRUE)
actuals <- original$ptratio[is.na(original$ptratio)]
actuals
predicteds <- rep(mean(data_backup2$ptratio, na.rm = TRUE), length(actuals))
predicteds
actuals <- original$ptratio[is.na(data$ptratio)]  #從本來沒有遺失值的資料中選出被插入遺失值的row
actuals
predicteds <- rep(mean(data_backup2$ptratio, na.rm = TRUE), length(actuals))
predicteds
regr.eval(trues = actuals,preds = predicteds)
library(DMwR)
data
#將目標變數移除再進行預測填補
names(data)
knnoutput<-knnImputation(data=data[,!names(data)%in% 'medv'])
knnoutput
names(data)%in% 'medv'
anyNA(knnoutput)
#評估準確度:
actuals <- original$ptratio[is.na(data$ptratio)]  #從本來沒有遺失值的資料中選出被插入遺失值的row >> 即為真實值
predicteds <- rep(mean(knnoutput$ptratio, na.rm = TRUE), length(actuals)) #預測值皆為平均值
regr.eval(trues = actuals,preds = predicteds)
#MAPE(平均絕對誤差百分比)為0.0957
library(rpart)
data
class_mod <- rpart(formula = rad ~ . -medv,
data = data[!is.na(data$rad),],
method = "class",
na.action = na.omit)
# 預測數值變數model
anova_mod <- rpart(formula = ptratio ~ . -medv,
data = data[!is.na(data),],
method = "anova",
na.action = na.omit)
str(data)
data[is.na(data$rad),]
rad_predict <- predict(object = class_mod,
newdata = data[is.na(data$rad),])#rad欄位有NA的row
ptratio_predict <- predict(object = anova_mod,
newdata = data[is.na(data$ptratio),])#ptratio欄位有NA的row
rad_predict
ptratio_predict
anova_mod
# 評估準確度:
actuals
predicteds <- ptratio_predict
predicteds
regr.eval(trues = actuals, preds = predicteds)
actuals <- original$rad[is.na(data$rad)]
actuals
colnames(rad_predict)
rad_predict
as.numeric(colnames(rad_predict)
apply(rad_predict, 1, which.max)
x<-apply(rad_predict, 1, which.max)
x
rad_predict[x]
actuals
str(rad_predict)
data$rad
as.numeric(colnames(rad_predict)[apply(rad_predict, 1, which.max)])
x
rad_predict[x]
colnames(rad_predict[x])
data$rad
str(rad_predict)
colnames(rad_predict)
colnames(rad_predict)[1]
colnames(rad_predict)[9]
x<-apply(rad_predict, 1, which.max)#把rad_predict矩陣中每一row中最大的值(機率)挑出
x
colnames(rad_predict)[x]
as.numeric(colnames(rad_predict)[x])
mean(actuals != predicteds)
actuals != predicteds
actuals
predicteds
predicteds <- as.numeric(colnames(rad_predict)[apply(rad_predict, 1, which.max)])
predicteds
actuals
actuals != predicteds
mean(actuals != predicteds)
library(mice)
install.packages('mice')
library(mice)
miceMod <- mice(data = data[,!names(data) %in% "medv"],
method = "rf", #可以指定單一或多個補值法for不同的欄位；只給一個補值法的話，就會用到所有欄位上
maxit = 5 #可以指定迭代次數，預設為五次
)
miceOutput <- complete(miceMod,action = 1) #預設action為第一組資料
miceOutput
anyNA(miceOutput)
actuals <- original$ptratio[is.na(data$ptratio)]
predicteds <- miceOutput[is.na(data$ptratio),"ptratio"]
actuals
predicteds
regr.eval(actuals,predicteds)
actuals <- original$rad[is.na(data$rad)]
predicteds <- miceOutput[is.na(data$rad),"rad"]
mean(actuals != predicteds)
actuals
predicteds
actuals != predicteds
mean(actuals != predicteds)
setwd("C:/Users/USER/Desktop/Github/R Project")
getwd()
df_train<-read.csv("train.csv")
df_test<-read.csv("test.csv")
str(df_train)
str(df_test)
head(df_train,10)
head(df_test,10)
summary(df_train)
df<-rbind(df_train, df_test)
head(df_train)
head(df_test)
str(df_train)
str(df_test)
hist(df_train$Sex)
df_train$Sex<-as.factor(df_train$Sex)
df_train$Sex
df_train$Sex<-as.factor(df_train$Sex,labels=c(0,1))
df_train$Sex<-factor(df_train$Sex,labels=c(0,1))
df_train$Sex
hist(df_train$Sex)
df_train$Sex<-as.numeric(df_train$Sex)
df_train$Sex
df_train<-read.csv("train.csv")
df_test<-read.csv("test.csv")
str(df_train)
str(df_test)
df_train_backup<-df_train
df_train$Sex<-factor(df_train$Sex,labels=c(0,1)) # 0:female;1:Male
df_train$Sex<-as.numeric(as.character(df_train$Sex))
df_train$Sex
hist(df_train$Sex)
hist(df_train$Sex)
hist(x=df_train$Sex,y=df_train$Survived)
new_df_train <-
df_train %>%
group_by(Sex) %>%
summarise(
survived<-length(Survived=1)
survived_rate<-survived/n()
) %>%
ungroup() %>%
as.data.frame()
new_df_train <-
df_train %>%
group_by(Sex) %>%
summarise(
survived<-length(Survived=1)
survived_rate<-survived/n()
)
df_train_Sex<-df_train[,c(2,5)]
df_train_Sex
head(df_train_Sex,10)
hist(df_train_Sex$Survived)
